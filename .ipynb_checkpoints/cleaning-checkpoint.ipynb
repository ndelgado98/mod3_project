{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the data cleaning phase of the project. The raw datasets have been downloaded from the Driven Data website. The datasets are as follows:\n",
    "\n",
    "\"test_set_values.csv\": the competition testing set, containing only the id and the target variable (\"status_group\")\n",
    "\n",
    "\"training_set_labels.csv\": the competition training set, containing the target variable\n",
    "\n",
    "\"training_set_values.csv\": the competition training set, containing all the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets into DataFrames\n",
    "df_inspect = pd.read_csv('test_set_values.csv')\n",
    "df2_inspect = pd.read_csv('training_set_labels.csv')\n",
    "df3_inspect = pd.read_csv('training_set_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing data set will be ignored for now, as it relates to the competition. The competition training data will be combined into a single DF for cleaning purposes, and will itself be split into testing/training/validation sets further down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining competition training sets\n",
    "df4_combo = df3_inspect.join(df2_inspect, rsuffix='_r')\n",
    "df5_combo = df4_combo.drop(['id_r'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features included in the dataset are described as follows (as per the Driven Date website):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **amount_tsh** - Total static head (amount water available to waterpoint)\n",
    "- **date_recorded** - The date the row was entered\n",
    "- **funder** - Who funded the well\n",
    "- **gps_height** - Altitude of the well\n",
    "- **installer** - Organization that installed the well\n",
    "- **longitude** - GPS coordinate\n",
    "- **latitude** - GPS coordinate\n",
    "- **wpt_name** - Name of the waterpoint if there is one\n",
    "- **num_private** -\n",
    "- **basin** - Geographic water basin\n",
    "- **subvillage** - Geographic location\n",
    "- **region** - Geographic location\n",
    "- **region_code** - Geographic location (coded)\n",
    "- **district_code** - Geographic location (coded)\n",
    "- **lga** - Geographic location\n",
    "- **ward** - Geographic location\n",
    "- **population** - Population around the well\n",
    "- **public_meeting** - True/False\n",
    "- **recorded_by** - Group entering this row of data\n",
    "- **scheme_management** - Who operates the waterpoint\n",
    "- **scheme_name** - Who operates the waterpoint\n",
    "- **permit** - If the waterpoint is permitted\n",
    "- **construction_year** - Year the waterpoint was constructed\n",
    "- **extraction_type** - The kind of extraction the waterpoint uses\n",
    "- **extraction_type_group** - The kind of extraction the waterpoint uses\n",
    "- **extraction_type_class** - The kind of extraction the waterpoint uses\n",
    "- **management** - How the waterpoint is managed\n",
    "- **management_group** - How the waterpoint is managed\n",
    "- **payment** - What the water costs\n",
    "- **payment_type** - What the water costs\n",
    "- **water_quality** - The quality of the water\n",
    "- **quality_group** - The quality of the water\n",
    "- **quantity** - The quantity of water\n",
    "- **quantity_group** - The quantity of water\n",
    "- **source** - The source of the water\n",
    "- **source_type** - The source of the water\n",
    "- **source_class** - The source of the water\n",
    "- **waterpoint_type** - The kind of waterpoint\n",
    "- **waterpoint_type_group** - The kind of waterpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features were inspected one by one to determine if any need to be edited or removed. Below are the features for which an issue has been identified:\n",
    "\n",
    "- **date_recorded**: deemed irrelevant for analysis - *to remove*\n",
    "- **funder**: missing values, and too many single instances - *to fill and to cut down*\n",
    "- **installer**: missing values, and too many single instances - *to fill and to cut down*\n",
    "- **wpt_name**: deemed irrelevant for analysis - *to remove*\n",
    "- **num_private**: empty feature - *to remove*\n",
    "- **subvillage**: deemed irrelevant for analysis - *to remove*\n",
    "- **region**: deemed irrelevant for analysis - *to remove*\n",
    "- **region_code**: deemed irrelevant for analysis - *to remove*\n",
    "- **district_code**: deemed irrelevant for analysis - *to remove*\n",
    "- **lga**: deemed irrelevant for analysis - *to remove*\n",
    "- **ward**: deemed irrelevant for analysis - *to remove*\n",
    "- **public_meeting**: deemed irrelevant for analysis - *to remove*\n",
    "- **recorded_by**: all values are the same, none missing - *to remove*\n",
    "- **scheme_management**: missing values, duplicate of 'management' - *to remove*\n",
    "- **scheme_name**: missing values, deemed irrelevant for analysis - *to remove*\n",
    "- **permit**: missing values - *to fill*\n",
    "- **construction_year**: mostly zero; not useful for analyis - *to convert to age in months and fill missing with median*\n",
    "- **extraction_type_group** - subsumed by 'extraction_type' - *to remove*\n",
    "- **extraction_type_class** - subsumed by 'extraction_type' - *to remove*\n",
    "- **payment_type**: duplicate of 'payment' - *to remove*\n",
    "- **water_quality**: subsumed by 'quality_group' - *to remove*\n",
    "- **quantity_group**: duplicate of 'quantity' - *to remove*\n",
    "- **source_type**: subsumed by 'source' - *to remove*\n",
    "- **source_class**: subsumed by 'source' - *to remove*\n",
    "- **waterpoint_type_group**: subsumed by 'waterpoint_type' - *to remove*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A specific point to mention is that the 'funder' and 'installer' variables have many singular instances, ie there are many organisations that have funded/installed a single well. This means that there is no useful insight to be gained from these features as they are, since a testing data point will probably not fit into any existing category here. To solve this, these two features will be limited to the top 6 installers and funders, and all remaining values will be grouped into a single value named 'small_org'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "### Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is created in order to clean the entire dataset. The function is documented below, and can also be used to clean the competition test set, if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to clean and rearrange dataframe\n",
    "\n",
    "def preprocess_clean(dataframe, cols_to_drop, cols_to_fill, col_order, target_name):\n",
    "    \n",
    "    \"\"\"Function to clean and rearrange dataframe for use in the model.\n",
    "    \n",
    "    The function will take the dataframe as an argument and perform the following operations:\n",
    "    - Fill 'construction year' nil values with median non-zero value\n",
    "    - Convert 'construction year' to age in years\n",
    "    - Remove the rows identified as irrelevant\n",
    "    - Fill categorical variable NAs with 'unknown'\n",
    "    - Limit funders and installers to top five, with remaining values grouped into single value\n",
    "    - Rearranges column order for readibility\n",
    "    \n",
    "    Args:\n",
    "        'dataframe': the dataframe to clean\n",
    "        'cols_to_drop': list of columns to drop from the dataframe\n",
    "        'cols_to_fill': list of categorical columns to fill\n",
    "        'col_order': list of columns in the desired order for the output\n",
    "        'target_name': name (as string) of target variable\n",
    "    \n",
    "    Returns:\n",
    "        A cleaned dataframe with the desired columns in the order specified\n",
    "    \"\"\"\n",
    "    \n",
    "    # creating copy of dataframe\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # converting 'construction_year' to age in years and filling zeros with median\n",
    "    if 'construction_year' in df.columns:\n",
    "        df.replace(0, np.nan, inplace=True)\n",
    "        median_x = df['construction_year'].median(skipna=True)\n",
    "        df['construction_year'].fillna(median_x, inplace=True)\n",
    "        df['age_years'] = round(2019 - df['construction_year'],0)\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # dropping columns identified above as irrelvant\n",
    "    df2 = df.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    # filling missing values with 'unknown' categorical\n",
    "    df2[cols_to_fill] = df2[cols_to_fill].fillna(value='unknown')\n",
    "    \n",
    "    # limiting installers to top 6 only, with remaining values grouped together\n",
    "    if 'installer' in df2.columns:\n",
    "        installer_series = df2['installer'].value_counts()\n",
    "        installer_series_2 = installer_series.sort_values(ascending=False)\n",
    "        installer_top_6 = installer_series_2.index[0:6]\n",
    "        installer_top_6_list = list(installer_top_6)\n",
    "        df2['installer'] = df2['installer'].apply(lambda x: x if x in installer_top_6_list else 'small_inst')\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # limiting funders to top 6 only, with remaining values grouped together\n",
    "    if 'funder' in df2.columns:\n",
    "        funder_series = df2['funder'].value_counts()\n",
    "        funder_series_2 = funder_series.sort_values(ascending=False)\n",
    "        funder_top_6 = funder_series_2.index[0:6]\n",
    "        funder_top_6_list = list(funder_top_6)\n",
    "        df2['funder'] = df2['funder'].apply(lambda x: x if x in funder_top_6_list else 'small_fund')\n",
    "    \n",
    "    else:\n",
    "        pass    \n",
    "    \n",
    "    # rearranging column order, and excluding target variable if not in dataframe\n",
    "    if target_name in df2.columns:\n",
    "        df3 = df2[col_order]\n",
    "    else:\n",
    "        list2 = order_cols[:order_cols.index(target_name)]+order_cols[order_cols.index(target_name)+1:]\n",
    "        df3 = df2[list2]\n",
    "    \n",
    "    df4 = df3.fillna(0)\n",
    "    \n",
    "    return df4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of columns to drop, in order to pass into the cleaning function\n",
    "drop_cols = ['date_recorded',\n",
    "                'wpt_name',\n",
    "                'num_private',\n",
    "                'subvillage',\n",
    "                'region',\n",
    "                'region_code',\n",
    "                'district_code',\n",
    "                'lga',\n",
    "                'ward',\n",
    "                'public_meeting',\n",
    "                'recorded_by',\n",
    "                'scheme_management',\n",
    "                'scheme_name',\n",
    "                'construction_year',\n",
    "                'extraction_type_group',\n",
    "                'extraction_type_class',\n",
    "                'payment_type',\n",
    "                'water_quality',\n",
    "                'quantity_group',\n",
    "                'source_type',\n",
    "                'source_class',\n",
    "                'waterpoint_type_group']\n",
    "\n",
    "# creating list of columns to fill with 'unknown'\n",
    "fill_cols = ['funder',\n",
    "            'installer',\n",
    "            'permit']\n",
    "\n",
    "# creating list of columns order\n",
    "order_cols = ['id',\n",
    "            'amount_tsh',\n",
    "            'funder',\n",
    "            'installer',\n",
    "            'gps_height',\n",
    "            'longitude',\n",
    "            'latitude',\n",
    "            'basin',\n",
    "            'population',\n",
    "            'permit',\n",
    "            'extraction_type',\n",
    "            'management',\n",
    "            'management_group',\n",
    "            'payment',\n",
    "            'quality_group',\n",
    "            'quantity',\n",
    "            'source',\n",
    "            'waterpoint_type',\n",
    "            'age_years',\n",
    "            'status_group',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                59400 non-null  float64\n",
      " 1   amount_tsh        59400 non-null  float64\n",
      " 2   funder            59400 non-null  object \n",
      " 3   installer         59400 non-null  object \n",
      " 4   gps_height        59400 non-null  float64\n",
      " 5   longitude         59400 non-null  float64\n",
      " 6   latitude          59400 non-null  float64\n",
      " 7   basin             59400 non-null  object \n",
      " 8   population        59400 non-null  float64\n",
      " 9   permit            59400 non-null  object \n",
      " 10  extraction_type   59400 non-null  object \n",
      " 11  management        59400 non-null  object \n",
      " 12  management_group  59400 non-null  object \n",
      " 13  payment           59400 non-null  object \n",
      " 14  quality_group     59400 non-null  object \n",
      " 15  quantity          59400 non-null  object \n",
      " 16  source            59400 non-null  object \n",
      " 17  waterpoint_type   59400 non-null  object \n",
      " 18  age_years         59400 non-null  float64\n",
      " 19  status_group      59400 non-null  object \n",
      "dtypes: float64(7), object(13)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# cleaning the datatset using the cleaning function\n",
    "df_clean = preprocess_clean(df5_combo, drop_cols, fill_cols, order_cols, 'status_group')\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14850 entries, 0 to 14849\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                14850 non-null  int64  \n",
      " 1   amount_tsh        14850 non-null  float64\n",
      " 2   funder            14850 non-null  object \n",
      " 3   installer         14850 non-null  object \n",
      " 4   gps_height        14850 non-null  float64\n",
      " 5   longitude         14850 non-null  float64\n",
      " 6   latitude          14850 non-null  float64\n",
      " 7   basin             14850 non-null  object \n",
      " 8   population        14850 non-null  float64\n",
      " 9   permit            14850 non-null  object \n",
      " 10  extraction_type   14850 non-null  object \n",
      " 11  management        14850 non-null  object \n",
      " 12  management_group  14850 non-null  object \n",
      " 13  payment           14850 non-null  object \n",
      " 14  quality_group     14850 non-null  object \n",
      " 15  quantity          14850 non-null  object \n",
      " 16  source            14850 non-null  object \n",
      " 17  waterpoint_type   14850 non-null  object \n",
      " 18  age_years         14850 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(12)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean_2 = preprocess_clean(df_inspect, drop_cols, fill_cols, order_cols, 'status_group')\n",
    "df_clean_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
